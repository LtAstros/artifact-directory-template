Title:
Occupational gender bias in DALL-E 2

Abstract:
DALL-E 2 is a model that processes natural language and returns a corresponding image or set of images. This model has, in the past two years, come under increasing scrutiny due to its biased results wherein certain genders or races are displayed more, often significantly more, than others. In July of 2022, OpenAI, the publishers of DALL-E 2, revealed that they had worked on methods to mitigate this bias that had resulted in a marked, visible improvement in the generated images. This is the claim that was tested over the course of this investigation; is DALL-E 2 still biased in terms of gender and occupation? In other words, are the image sets generated by the algorithm relatively balanced? In order to test this claim, ten professions were selected from the Bureau of Labor Statisticsâ€™ listing of occupations in the United States. Half of the professions were selected as slightly male dominated (over 50% of the gender make up for the job was male), while the other half were selected as slightly female dominated. Upon testing these inputs through DALL-E 2 and tagging the resulting images as either male-presenting or female-presenting, it was found that, if not the model itself, the DALL-E 2 API is still extremely biased at least across the axes of gender and occupation. 
